{
    "training_config": {
        "model_id": "/mnt/zhaorunsong/models/TinyLlama/TinyLlama_v1.1",
        "segment_len": 510,
        "total_batch_size": 32,
        "batch_size_per_device": 1,
        "device_count": 2,
        "gradient_accumulation_steps": 16,
        "learning_rate": 0.0001,
        "max_grad_norm": 1.0,
        "log_step": 10,
        "valid_step": 1000,
        "save_step": 10
    },
    "task_config": {
        "segment_size": 510,
        "mem_size": 34,
        "head_num": 15,
        "segment_num": 2,
        "task_type": "Compress"
    },
    "data_config": {
        "dataset_repo": "DKYoon/SlimPajama-6B",
        "hf_token": "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",
        "token_num": 1000000000,
        "min_len": 510,
        "model_id": "/mnt/zhaorunsong/models/TinyLlama/TinyLlama_v1.1",
        "instruction_dataset_repo": "sggetao/PwC"
    },
    "Total_parameters": 1117640704,
    "Trainable_parameters": 17684480,
    "Embedding_parameters": 4902912,
    "non-Embedding_parameters": 12781568
}